# Real-Estate-Property-Finder-Data-Visualization-Track-ITI
### Project Description and Step-by-Step  The project is an full end-to-end Business Intelligence system for real-estate analytics. The workflow begins with **web scraping and dataset collection**, followed by cleaning, modeling, warehouse construction, and dashboard visualization. The core correction is that **all datasets were obtained from external public sources through scraping or open repositories**, not from direct company access.   ---  ## 1. Data Collection (Actual Sources)  ### Listings Data — Property Finder (Web Scraping)  The main dataset consists of real-estate listings scraped directly from the Property Finder website using a custom Python scraping pipeline.  **Collected attributes include:**  * Property price * Location and city * Developer/company * Property type * Size and amenities * Listing status  Approximately **99,000 listings** were extracted. This dataset represents real market behavior and forms the backbone of the analysis.   ---  ### Agents Data — Fastbase (Web Scraping)  Agent information was scraped from the Fastbase website.  **Collected attributes include:**  * Agent profiles * Experience details * Agency affiliations * Contact or professional metadata  Around **3,600 agent records** were collected and later cleaned and standardized to integrate with the listings and leads datasets.   ---  ### Campaign & Reviews Data — Kaggle (Open Dataset)  Marketing campaign and customer review datasets were downloaded from Kaggle.  **Dataset size:**  * ~38,000 campaign records * ~49,000 customer reviews  These datasets enrich the system with marketing and customer sentiment dimensions.   ---  ## 2. Data Cleaning and Integration  After collection, all datasets were merged into a unified analytical dataset.  Key preprocessing steps:  * Removing duplicates * Handling missing values * Standardizing formats * Assigning leads to properties, agents, and campaigns * Validating relationships between entities  An ERD was created to formalize relationships between all entities.   ---  ## 3. Data Modeling (Galaxy Schema)  A Galaxy Schema was implemented to support integrated analytics across multiple business processes.  **Fact tables**  * Fact Leads * Fact Sales  **Dimension tables**  * Agents * Listings * Leads * Campaigns * Reviews * Date  This schema enables scalable cross-domain analysis and KPI tracking.   ---  ## 4. BI Queries and Analytical Layer  Oracle SQL and PL/SQL were used to implement advanced analytics:  * Conversion rate calculations * Agent performance metrics * Campaign ROI analysis * Sales anomaly detection * Funnel analysis from campaign to customer review  These queries power the BI dashboards.   ---  ## 5. Data Warehouse and ETL  A centralized warehouse was built in MS SQL Server and populated through SSIS ETL pipelines:  * Extract → Transform → Load automation * Schema validation * Consistent data refresh workflow  This ensures reliable analytical storage.   ---  ## 6. Power BI Dashboards  Interactive dashboards visualize:  * Market trends * Agent performance * Campaign efficiency * Lead conversion funnels * Sales KPIs * Customer satisfaction  These dashboards convert raw data into actionable insights. 
